# 데이터

현실 세계의 정보를 수치화한 값들(Feature)


## 데이터 크기(shape): 

    행(row: 샘플 수 ), 열(column: 피처수)

    특징: 데이터 구조 파악 첫단계

## 출처(Source):

    데이터의 수집 경로(CSV,DB, API, 센서 등)

    특징: 데이터의 신뢰성과 품질 판단

## EDA(탐색적 데이터 분석)
데이터를 이해하는 과정 , 모델링보다 먼저 '무슨데이터인지' 감 잡는 단계

### 히스토그램 :

- 수치형 변수의 분포 확인

- 평균, 범위 왜도(비대칭성) 파악

### 스캐터 플롯(산점도) :

- 두 변수 간 관계 시각화(상관관계 확인)

### 박스플롯 :

- 중앙값, 사분위수, 이상치 확인

## 전처리 / 가공 단계

### 결측처리
- 누락된 값 제거(drop) 또는 대체

- 학습오류방지

### 이상치 처리
- 극단값을 제거하거나 조정(z-score,IQR)

- 평균 왜곡 방지

### 스케일링
- 값의 범위를 맞춤(0~1, 평균 0 표준편차 1)

- 모델의 학습 안정화

### 정규화(0~1 범위로 조정)
- 거리 기반 모델(KNN, SVM)에서 중요

### 표준화(평균 0, 분산 1)
- 회귀,SVM 등에서 중요

### RobustScaler
- 중앙값 중심으로 스케일링

- 이상치에 강함

### 인코딩
- 문자 -> 숫자 변환

- 모델이 문자 이해 불가하므로

### 피처 엔지니어링
- 기존 데이터에서 새피처 파생

- 의미있는 정보 추가

### 파생피처

- 변수끼리 결합(예: 소득/연령)

- 관계 강화

### 차원축소(PCA)(데이터축소, 노이즈제거)
- 속도 향상, 시각화 용이

### 샘플링
- 클래스 불균형 조정
- 학습 편향 방지

### 언어모델 전처리
- 토큰화, 불용어제거, 어간/표제어 추출

- 텍스트를 벡터로 수치화

- 자연어처리(NLP) 모델입력을 위해 필수

** 전처리는 모델이 데이터를 잘 이해하도록 돕는 청소 과정

## 모델링 단계
정제된 데이터를 기반으로 학습 알고리즘(모델)을 사용하여 예측 및 분류를 수행
